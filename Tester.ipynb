{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f2fc9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Load the trained SVC classifier from the pickle file\n",
    "with open('svm_classifier.pkl', 'rb') as file:\n",
    "    loaded_svm_classifier = pickle.load(file)\n",
    "\n",
    "# Specify the file path for the new dataset\n",
    "new_file_path = \"data_collected_errorstat_wo_noise_1_run=250.parquet\"\n",
    "\n",
    "# Use pyarrow to read the new dataset\n",
    "new_table = pq.read_table(new_file_path)\n",
    "\n",
    "# Convert the new table to a pandas DataFrame if needed\n",
    "new_df = new_table.to_pandas()\n",
    "new_df['ID'] = range(len(new_df))\n",
    "\n",
    "# Perform any necessary data preprocessing for the new dataset\n",
    "# ...\n",
    "\n",
    "# Extract features from the new dataset (similar to previous code)\n",
    "X_new = new_df[['point_x_shifted_real', 'point_x_shifted_imag']]\n",
    "\n",
    "# Use the loaded SVM classifier to make predictions on the new dataset\n",
    "y_pred_new = loaded_svm_classifier.predict(X_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e618586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values using the SVM classifier for the entire dataset\n",
    "new_df['Decoded'] = y_pred_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c976a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 'Decoded' column: 0.9661102294921875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_decoded = accuracy_score(new_df['point_label'], new_df['Decoded'])\n",
    "\n",
    "print(\"Accuracy for 'Decoded' column:\", accuracy_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b02c3f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of LOF IDs: 3269\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = new_df[['point_x_shifted_real', 'point_x_shifted_imag']]\n",
    "y = new_df['point_label']\n",
    "all_predictions = loaded_svm_classifier.predict(X)\n",
    "# Create a DataFrame with predicted and true labels\n",
    "dfc = pd.DataFrame({'point_x_shifted_real': X['point_x_shifted_real'],\n",
    "                   'point_x_shifted_imag': X['point_x_shifted_imag'],\n",
    "                   'predicted_point_label': all_predictions,\n",
    "                   'true_point_label': y})\n",
    "\n",
    "# Get a list of unique class labels\n",
    "unique_labels = dfc['true_point_label'].unique()\n",
    "\n",
    "\n",
    "# Create a scatter plot for each class\n",
    "for label in unique_labels:\n",
    "    # Filter the data for the current class\n",
    "    data_class = dfc[dfc['true_point_label'] == label]\n",
    "    \n",
    "# THE LOF    \n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Define LOF parameters\n",
    "n_neighbors = 20  # Number of neighbors to consider\n",
    "contamination = 0.05  # Expected proportion of outliers\n",
    "\n",
    "# Create a dictionary to store the LOF results for each class\n",
    "lof_results = {}\n",
    "\n",
    "# Get a list of unique class labels\n",
    "unique_labels = dfc['true_point_label'].unique()\n",
    "\n",
    "# Perform LOF detection for each class\n",
    "for label in unique_labels:\n",
    "    # Filter the data for the current class\n",
    "    data_class = dfc[dfc['true_point_label'] == label]\n",
    "    \n",
    "    # Extract the features for LOF detection\n",
    "    features = data_class[['point_x_shifted_real', 'point_x_shifted_imag']]\n",
    "    \n",
    "    # Initialize the LOF model\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    \n",
    "    # Fit the LOF model to the data\n",
    "    lof.fit(features)\n",
    "    \n",
    "    # Predict the LOF scores for the data\n",
    "    lof_scores = lof.negative_outlier_factor_\n",
    "    \n",
    "    # Find the IDs of the LOF points\n",
    "    lof_ids = data_class.index[lof_scores.argsort()[:int(len(lof_scores) * contamination)]]\n",
    "    \n",
    "    # Store the results in the dictionary\n",
    "    lof_results[label] = lof_ids\n",
    "\n",
    "\n",
    "total_lof_ids = sum(len(ids) for ids in lof_results.values())\n",
    "print(\"Total number of LOF IDs:\", total_lof_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20e3426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on selected data: 0.6099724686448456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cg\\AppData\\Local\\Temp\\ipykernel_5860\\1684922084.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  selected_data = selected_data.append(class_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "with open('decision_tree_classifier.pkl', 'rb') as file:\n",
    "    loaded_dt_classifier = pickle.load(file)\n",
    "\n",
    "selected_data = pd.DataFrame()\n",
    "  \n",
    "\n",
    "for label, lof_ids in lof_results.items():\n",
    "    # Select the rows from 'df' for the current class\n",
    "    class_data = new_df[new_df['ID'].isin(lof_ids)]\n",
    "    selected_data = selected_data.append(class_data, ignore_index=True)\n",
    "\n",
    "# Define X and y for Decision Tree classification\n",
    "X_selected = selected_data[['point_x_shifted_real', 'point_x_shifted_imag']]\n",
    "y_selected = selected_data['point_label']\n",
    "\n",
    "y_pred_selected = loaded_dt_classifier.predict(X_selected)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_selected = accuracy_score(y_selected, y_pred_selected)\n",
    "print(\"Accuracy on selected data:\", accuracy_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e31104b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the unique class labels and their LOF IDs\n",
    "for label, lof_ids in lof_results.items():\n",
    "    # Select rows with matching 'ID' values\n",
    "    mask = new_df['ID'].isin(lof_ids)\n",
    "    \n",
    "    # Get the corresponding data\n",
    "    selected_data = new_df[mask]\n",
    "    \n",
    "    # Predict using the Decision Tree classifier\n",
    "    predictions = loaded_dt_classifier.predict(selected_data[['point_x_shifted_real', 'point_x_shifted_imag']])\n",
    "    \n",
    "    # Update the 'Decoded' column for these rows with the Decision Tree predictions\n",
    "    new_df.loc[mask, 'Decoded'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "123c0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 'Decoded' column: 0.9707794189453125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate accuracy for 'Decoded' and 'point_label' columns\n",
    "accuracy_decoded = accuracy_score(new_df['point_label'], new_df['Decoded'])\n",
    "\n",
    "print(\"Accuracy for 'Decoded' column:\", accuracy_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfea83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb9daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e02ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2957ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
